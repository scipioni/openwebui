# =============================================================================
# Open WebUI Docker Compose Configuration
# =============================================================================
# Copy this file to .env and customize the values below
# Command: cp .env.example .env

# -----------------------------------------------------------------------------
# NETWORK CONFIGURATION
# -----------------------------------------------------------------------------

# Port on which Open WebUI will be accessible
OPENWEBUI_PORT=8080

# External Ollama API endpoint
# For Docker Desktop on Windows/Mac, use: http://host.docker.internal:11434
# For Linux, use your host IP address: http://192.168.1.XXX:11434
OLLAMA_BASE_URL=http://host.docker.internal:11434

# -----------------------------------------------------------------------------
# AUTHENTICATION & SECURITY
# -----------------------------------------------------------------------------

# Enable/disable authentication (true/false)
# Set to false for local development without login
WEBUI_AUTH=false

# Allow new user signups (true/false)
ENABLE_SIGNUP=false

# Secret key for session encryption (generate a strong random string)
# You can generate one with: openssl rand -hex 32
WEBUI_SECRET_KEY=your-secret-key-change-this-in-production

# Default role for new users (admin/user)
DEFAULT_USER_ROLE=user

# -----------------------------------------------------------------------------
# MODEL CONFIGURATION
# -----------------------------------------------------------------------------

# Comma-separated list of default models to show
# Example: llama2,mistral,codellama
# Leave empty to show all available models from Ollama
DEFAULT_MODELS=

# -----------------------------------------------------------------------------
# RAG (Retrieval-Augmented Generation) SETTINGS
# -----------------------------------------------------------------------------

# Enable web search in RAG (true/false)
ENABLE_RAG_WEB_SEARCH=false

# Embedding model for RAG
RAG_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Document chunk size for RAG processing
CHUNK_SIZE=1500

# Overlap between document chunks
CHUNK_OVERLAP=100

# -----------------------------------------------------------------------------
# IMAGE GENERATION
# -----------------------------------------------------------------------------

# Enable image generation features (true/false)
ENABLE_IMAGE_GENERATION=false

# Image generation engine (automatic/openai/comfyui)
IMAGE_GENERATION_ENGINE=

# -----------------------------------------------------------------------------
# LOGGING & MONITORING
# -----------------------------------------------------------------------------

# Log level (DEBUG/INFO/WARNING/ERROR)
WEBUI_LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# ADDITIONAL SETTINGS
# -----------------------------------------------------------------------------

# Enable community model sharing (true/false)
ENABLE_COMMUNITY_SHARING=false